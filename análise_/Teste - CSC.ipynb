{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "101360f0-f3b6-4ceb-9e9c-9cbe0107bf09",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyiris.ingestion.extract import ExtractService, FileReader\n",
    "from pyiris.ingestion.load import LoadService, FileWriter\n",
    "from pyiris.ingestion.config.file_system_config import FileSystemConfig\n",
    "from pyiris.infrastructure import Spark\n",
    "import pyspark.sql.functions as f\n",
    "iris_spark = Spark()\n",
    "from datetime import timedelta, date\n",
    "import datetime\n",
    "spark.conf.set(\"spark.sql.sources.partitionOverwriteMode\",\"dynamic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "daa7608d-d901-4cc9-adda-ce6a2e802719",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">/mnt/consumezoneprod/Brazil/Sales/CustomerExperience/ZendeskSav/FatoSolicitacoesRota\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">/mnt/consumezoneprod/Brazil/Sales/CustomerExperience/ZendeskSav/FatoSolicitacoesRota\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n",
       "<span class=\"ansi-red-fg\">AnalysisException</span>                         Traceback (most recent call last)\n",
       "<span class=\"ansi-green-fg\">&lt;command-2293093804025023&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">      2</span> country <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">&#39;Brazil&#39;</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">      3</span> path_origin_otif2 <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">&#39;Sales/CustomerExperience/ZendeskSav/FatoSolicitacoesRota&#39;</span>\n",
       "<span class=\"ansi-green-fg\">----&gt; 4</span><span class=\"ansi-red-fg\"> </span>df_valid1 <span class=\"ansi-blue-fg\">=</span> FileReader<span class=\"ansi-blue-fg\">(</span>table_id<span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">&#39;df_valid1&#39;</span><span class=\"ansi-blue-fg\">,</span> data_lake_zone<span class=\"ansi-blue-fg\">=</span> lake_zone_origin<span class=\"ansi-blue-fg\">,</span> country  <span class=\"ansi-blue-fg\">=</span> country<span class=\"ansi-blue-fg\">,</span> path <span class=\"ansi-blue-fg\">=</span> path_origin_otif2<span class=\"ansi-blue-fg\">,</span> format <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">&#39;parquet&#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>consume<span class=\"ansi-blue-fg\">(</span>spark<span class=\"ansi-blue-fg\">=</span>iris_spark<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">      5</span> \n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">      6</span> df_valid1<span class=\"ansi-blue-fg\">.</span>createOrReplaceTempView<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;df_valid1&#39;</span><span class=\"ansi-blue-fg\">)</span>\n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/python/lib/python3.8/site-packages/pyiris/ingestion/extract/readers/file_reader.py</span> in <span class=\"ansi-cyan-fg\">consume</span><span class=\"ansi-blue-fg\">(self, spark, filter)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    103</span>         <span class=\"ansi-green-fg\">if</span> result<span class=\"ansi-blue-fg\">.</span>is_right<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    104</span>             print<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>full_path<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-fg\">--&gt; 105</span><span class=\"ansi-red-fg\">             dataframe = spark.read(\n",
       "</span><span class=\"ansi-green-intense-fg ansi-bold\">    106</span>                 format<span class=\"ansi-blue-fg\">=</span>self<span class=\"ansi-blue-fg\">.</span>format<span class=\"ansi-blue-fg\">,</span> options<span class=\"ansi-blue-fg\">=</span>self<span class=\"ansi-blue-fg\">.</span>options<span class=\"ansi-blue-fg\">,</span> path<span class=\"ansi-blue-fg\">=</span>self<span class=\"ansi-blue-fg\">.</span>full_path\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    107</span>             )\n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/python/lib/python3.8/site-packages/pyiris/infrastructure/spark/spark.py</span> in <span class=\"ansi-cyan-fg\">read</span><span class=\"ansi-blue-fg\">(self, format, path, options)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     40</span>         <span class=\"ansi-green-fg\">if</span> options <span class=\"ansi-green-fg\">is</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">:</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     41</span>             options <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">{</span><span class=\"ansi-blue-fg\">}</span>\n",
       "<span class=\"ansi-green-fg\">---&gt; 42</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>session<span class=\"ansi-blue-fg\">.</span>read<span class=\"ansi-blue-fg\">.</span>load<span class=\"ansi-blue-fg\">(</span>path<span class=\"ansi-blue-fg\">=</span>path<span class=\"ansi-blue-fg\">,</span> format<span class=\"ansi-blue-fg\">=</span>format<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>options<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     43</span> \n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     44</span>     def read_jdbc(\n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/readwriter.py</span> in <span class=\"ansi-cyan-fg\">load</span><span class=\"ansi-blue-fg\">(self, path, format, schema, **options)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    202</span>         self<span class=\"ansi-blue-fg\">.</span>options<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">**</span>options<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    203</span>         <span class=\"ansi-green-fg\">if</span> isinstance<span class=\"ansi-blue-fg\">(</span>path<span class=\"ansi-blue-fg\">,</span> str<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n",
       "<span class=\"ansi-green-fg\">--&gt; 204</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>_df<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_jreader<span class=\"ansi-blue-fg\">.</span>load<span class=\"ansi-blue-fg\">(</span>path<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    205</span>         <span class=\"ansi-green-fg\">elif</span> path <span class=\"ansi-green-fg\">is</span> <span class=\"ansi-green-fg\">not</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">:</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    206</span>             <span class=\"ansi-green-fg\">if</span> type<span class=\"ansi-blue-fg\">(</span>path<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">!=</span> list<span class=\"ansi-blue-fg\">:</span>\n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1302</span> \n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1303</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-fg\">-&gt; 1304</span><span class=\"ansi-red-fg\">         return_value = get_return_value(\n",
       "</span><span class=\"ansi-green-intense-fg ansi-bold\">   1305</span>             answer, self.gateway_client, self.target_id, self.name)\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1306</span> \n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    121</span>                 <span class=\"ansi-red-fg\"># Hide where the exception came from that shows a non-Pythonic</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    122</span>                 <span class=\"ansi-red-fg\"># JVM exception message.</span>\n",
       "<span class=\"ansi-green-fg\">--&gt; 123</span><span class=\"ansi-red-fg\">                 </span><span class=\"ansi-green-fg\">raise</span> converted <span class=\"ansi-green-fg\">from</span> <span class=\"ansi-green-fg\">None</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    124</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    125</span>                 <span class=\"ansi-green-fg\">raise</span>\n",
       "\n",
       "<span class=\"ansi-red-fg\">AnalysisException</span>: Path does not exist: dbfs:/mnt/consumezoneprod/Brazil/Sales/CustomerExperience/ZendeskSav/FatoSolicitacoesRota</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">AnalysisException</span>                         Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-2293093804025023&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      2</span> country <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">&#39;Brazil&#39;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      3</span> path_origin_otif2 <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">&#39;Sales/CustomerExperience/ZendeskSav/FatoSolicitacoesRota&#39;</span>\n<span class=\"ansi-green-fg\">----&gt; 4</span><span class=\"ansi-red-fg\"> </span>df_valid1 <span class=\"ansi-blue-fg\">=</span> FileReader<span class=\"ansi-blue-fg\">(</span>table_id<span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">&#39;df_valid1&#39;</span><span class=\"ansi-blue-fg\">,</span> data_lake_zone<span class=\"ansi-blue-fg\">=</span> lake_zone_origin<span class=\"ansi-blue-fg\">,</span> country  <span class=\"ansi-blue-fg\">=</span> country<span class=\"ansi-blue-fg\">,</span> path <span class=\"ansi-blue-fg\">=</span> path_origin_otif2<span class=\"ansi-blue-fg\">,</span> format <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">&#39;parquet&#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>consume<span class=\"ansi-blue-fg\">(</span>spark<span class=\"ansi-blue-fg\">=</span>iris_spark<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      5</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">      6</span> df_valid1<span class=\"ansi-blue-fg\">.</span>createOrReplaceTempView<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;df_valid1&#39;</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.8/site-packages/pyiris/ingestion/extract/readers/file_reader.py</span> in <span class=\"ansi-cyan-fg\">consume</span><span class=\"ansi-blue-fg\">(self, spark, filter)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    103</span>         <span class=\"ansi-green-fg\">if</span> result<span class=\"ansi-blue-fg\">.</span>is_right<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    104</span>             print<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>full_path<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">--&gt; 105</span><span class=\"ansi-red-fg\">             dataframe = spark.read(\n</span><span class=\"ansi-green-intense-fg ansi-bold\">    106</span>                 format<span class=\"ansi-blue-fg\">=</span>self<span class=\"ansi-blue-fg\">.</span>format<span class=\"ansi-blue-fg\">,</span> options<span class=\"ansi-blue-fg\">=</span>self<span class=\"ansi-blue-fg\">.</span>options<span class=\"ansi-blue-fg\">,</span> path<span class=\"ansi-blue-fg\">=</span>self<span class=\"ansi-blue-fg\">.</span>full_path\n<span class=\"ansi-green-intense-fg ansi-bold\">    107</span>             )\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.8/site-packages/pyiris/infrastructure/spark/spark.py</span> in <span class=\"ansi-cyan-fg\">read</span><span class=\"ansi-blue-fg\">(self, format, path, options)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     40</span>         <span class=\"ansi-green-fg\">if</span> options <span class=\"ansi-green-fg\">is</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     41</span>             options <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">{</span><span class=\"ansi-blue-fg\">}</span>\n<span class=\"ansi-green-fg\">---&gt; 42</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>session<span class=\"ansi-blue-fg\">.</span>read<span class=\"ansi-blue-fg\">.</span>load<span class=\"ansi-blue-fg\">(</span>path<span class=\"ansi-blue-fg\">=</span>path<span class=\"ansi-blue-fg\">,</span> format<span class=\"ansi-blue-fg\">=</span>format<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>options<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     43</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">     44</span>     def read_jdbc(\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/readwriter.py</span> in <span class=\"ansi-cyan-fg\">load</span><span class=\"ansi-blue-fg\">(self, path, format, schema, **options)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    202</span>         self<span class=\"ansi-blue-fg\">.</span>options<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">**</span>options<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    203</span>         <span class=\"ansi-green-fg\">if</span> isinstance<span class=\"ansi-blue-fg\">(</span>path<span class=\"ansi-blue-fg\">,</span> str<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 204</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>_df<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_jreader<span class=\"ansi-blue-fg\">.</span>load<span class=\"ansi-blue-fg\">(</span>path<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    205</span>         <span class=\"ansi-green-fg\">elif</span> path <span class=\"ansi-green-fg\">is</span> <span class=\"ansi-green-fg\">not</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    206</span>             <span class=\"ansi-green-fg\">if</span> type<span class=\"ansi-blue-fg\">(</span>path<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">!=</span> list<span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1302</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1303</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">-&gt; 1304</span><span class=\"ansi-red-fg\">         return_value = get_return_value(\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1305</span>             answer, self.gateway_client, self.target_id, self.name)\n<span class=\"ansi-green-intense-fg ansi-bold\">   1306</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    121</span>                 <span class=\"ansi-red-fg\"># Hide where the exception came from that shows a non-Pythonic</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    122</span>                 <span class=\"ansi-red-fg\"># JVM exception message.</span>\n<span class=\"ansi-green-fg\">--&gt; 123</span><span class=\"ansi-red-fg\">                 </span><span class=\"ansi-green-fg\">raise</span> converted <span class=\"ansi-green-fg\">from</span> <span class=\"ansi-green-fg\">None</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    124</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    125</span>                 <span class=\"ansi-green-fg\">raise</span>\n\n<span class=\"ansi-red-fg\">AnalysisException</span>: Path does not exist: dbfs:/mnt/consumezoneprod/Brazil/Sales/CustomerExperience/ZendeskSav/FatoSolicitacoesRota</div>",
       "errorSummary": "<span class=\"ansi-red-fg\">AnalysisException</span>: Path does not exist: dbfs:/mnt/consumezoneprod/Brazil/Sales/CustomerExperience/ZendeskSav/FatoSolicitacoesRota",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lake_zone_origin = 'consumezoneprod'\n",
    "country = 'Brazil'\n",
    "path_origin_otif2 = 'Sales/CustomerExperience/ZendeskSav/FatoSolicitacoesRota'\n",
    "df_valid1 = FileReader(table_id= 'df_valid1', data_lake_zone= lake_zone_origin, country  = country, path = path_origin_otif2, format = 'parquet').consume(spark=iris_spark)\n",
    "\n",
    "df_valid1.createOrReplaceTempView('df_valid1')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0aeab47a-72ca-4fc7-8b91-8e10b5983ade",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n",
       "<span class=\"ansi-red-fg\">AnalysisException</span>                         Traceback (most recent call last)\n",
       "<span class=\"ansi-green-fg\">&lt;command-2293093804025024&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">      5</span>     display<span class=\"ansi-blue-fg\">(</span>df<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">      6</span>     <span class=\"ansi-green-fg\">return</span> df\n",
       "<span class=\"ansi-green-fg\">----&gt; 7</span><span class=\"ansi-red-fg\">   </span>_sqldf <span class=\"ansi-blue-fg\">=</span> ____databricks_percent_sql<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">      8</span> <span class=\"ansi-green-fg\">finally</span><span class=\"ansi-blue-fg\">:</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">      9</span>   <span class=\"ansi-green-fg\">del</span> ____databricks_percent_sql\n",
       "\n",
       "<span class=\"ansi-green-fg\">&lt;command-2293093804025024&gt;</span> in <span class=\"ansi-cyan-fg\">____databricks_percent_sql</span><span class=\"ansi-blue-fg\">()</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">      2</span>   <span class=\"ansi-green-fg\">def</span> ____databricks_percent_sql<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">      3</span>     <span class=\"ansi-green-fg\">import</span> base64\n",
       "<span class=\"ansi-green-fg\">----&gt; 4</span><span class=\"ansi-red-fg\">     </span>df <span class=\"ansi-blue-fg\">=</span> spark<span class=\"ansi-blue-fg\">.</span>sql<span class=\"ansi-blue-fg\">(</span>base64<span class=\"ansi-blue-fg\">.</span>standard_b64decode<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;c2VsZWN0ICogZnJvbSBkZl92YWxpZDEKTElNSVQgMTAw&#34;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>decode<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">      5</span>     display<span class=\"ansi-blue-fg\">(</span>df<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">      6</span>     <span class=\"ansi-green-fg\">return</span> df\n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansi-cyan-fg\">sql</span><span class=\"ansi-blue-fg\">(self, sqlQuery)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    775</span>         <span class=\"ansi-blue-fg\">[</span>Row<span class=\"ansi-blue-fg\">(</span>f1<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">,</span> f2<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">&#39;row1&#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> Row<span class=\"ansi-blue-fg\">(</span>f1<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">2</span><span class=\"ansi-blue-fg\">,</span> f2<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">&#39;row2&#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> Row<span class=\"ansi-blue-fg\">(</span>f1<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">3</span><span class=\"ansi-blue-fg\">,</span> f2<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">&#39;row3&#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">]</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    776</span>         &#34;&#34;&#34;\n",
       "<span class=\"ansi-green-fg\">--&gt; 777</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> DataFrame<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_jsparkSession<span class=\"ansi-blue-fg\">.</span>sql<span class=\"ansi-blue-fg\">(</span>sqlQuery<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">.</span>_wrapped<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    778</span> \n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    779</span>     <span class=\"ansi-green-fg\">def</span> table<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> tableName<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1302</span> \n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1303</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-fg\">-&gt; 1304</span><span class=\"ansi-red-fg\">         return_value = get_return_value(\n",
       "</span><span class=\"ansi-green-intense-fg ansi-bold\">   1305</span>             answer, self.gateway_client, self.target_id, self.name)\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1306</span> \n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    121</span>                 <span class=\"ansi-red-fg\"># Hide where the exception came from that shows a non-Pythonic</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    122</span>                 <span class=\"ansi-red-fg\"># JVM exception message.</span>\n",
       "<span class=\"ansi-green-fg\">--&gt; 123</span><span class=\"ansi-red-fg\">                 </span><span class=\"ansi-green-fg\">raise</span> converted <span class=\"ansi-green-fg\">from</span> <span class=\"ansi-green-fg\">None</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    124</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    125</span>                 <span class=\"ansi-green-fg\">raise</span>\n",
       "\n",
       "<span class=\"ansi-red-fg\">AnalysisException</span>: Table or view not found: df_valid1; line 1 pos 14;\n",
       "&#39;GlobalLimit 100\n",
       "+- &#39;LocalLimit 100\n",
       "   +- &#39;Project [*]\n",
       "      +- &#39;UnresolvedRelation [df_valid1], [], false\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">AnalysisException</span>                         Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-2293093804025024&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      5</span>     display<span class=\"ansi-blue-fg\">(</span>df<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      6</span>     <span class=\"ansi-green-fg\">return</span> df\n<span class=\"ansi-green-fg\">----&gt; 7</span><span class=\"ansi-red-fg\">   </span>_sqldf <span class=\"ansi-blue-fg\">=</span> ____databricks_percent_sql<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      8</span> <span class=\"ansi-green-fg\">finally</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      9</span>   <span class=\"ansi-green-fg\">del</span> ____databricks_percent_sql\n\n<span class=\"ansi-green-fg\">&lt;command-2293093804025024&gt;</span> in <span class=\"ansi-cyan-fg\">____databricks_percent_sql</span><span class=\"ansi-blue-fg\">()</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      2</span>   <span class=\"ansi-green-fg\">def</span> ____databricks_percent_sql<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      3</span>     <span class=\"ansi-green-fg\">import</span> base64\n<span class=\"ansi-green-fg\">----&gt; 4</span><span class=\"ansi-red-fg\">     </span>df <span class=\"ansi-blue-fg\">=</span> spark<span class=\"ansi-blue-fg\">.</span>sql<span class=\"ansi-blue-fg\">(</span>base64<span class=\"ansi-blue-fg\">.</span>standard_b64decode<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;c2VsZWN0ICogZnJvbSBkZl92YWxpZDEKTElNSVQgMTAw&#34;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>decode<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      5</span>     display<span class=\"ansi-blue-fg\">(</span>df<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      6</span>     <span class=\"ansi-green-fg\">return</span> df\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansi-cyan-fg\">sql</span><span class=\"ansi-blue-fg\">(self, sqlQuery)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    775</span>         <span class=\"ansi-blue-fg\">[</span>Row<span class=\"ansi-blue-fg\">(</span>f1<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">,</span> f2<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">&#39;row1&#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> Row<span class=\"ansi-blue-fg\">(</span>f1<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">2</span><span class=\"ansi-blue-fg\">,</span> f2<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">&#39;row2&#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> Row<span class=\"ansi-blue-fg\">(</span>f1<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">3</span><span class=\"ansi-blue-fg\">,</span> f2<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">&#39;row3&#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">]</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    776</span>         &#34;&#34;&#34;\n<span class=\"ansi-green-fg\">--&gt; 777</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> DataFrame<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_jsparkSession<span class=\"ansi-blue-fg\">.</span>sql<span class=\"ansi-blue-fg\">(</span>sqlQuery<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">.</span>_wrapped<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    778</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    779</span>     <span class=\"ansi-green-fg\">def</span> table<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> tableName<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1302</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1303</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">-&gt; 1304</span><span class=\"ansi-red-fg\">         return_value = get_return_value(\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1305</span>             answer, self.gateway_client, self.target_id, self.name)\n<span class=\"ansi-green-intense-fg ansi-bold\">   1306</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    121</span>                 <span class=\"ansi-red-fg\"># Hide where the exception came from that shows a non-Pythonic</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    122</span>                 <span class=\"ansi-red-fg\"># JVM exception message.</span>\n<span class=\"ansi-green-fg\">--&gt; 123</span><span class=\"ansi-red-fg\">                 </span><span class=\"ansi-green-fg\">raise</span> converted <span class=\"ansi-green-fg\">from</span> <span class=\"ansi-green-fg\">None</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    124</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    125</span>                 <span class=\"ansi-green-fg\">raise</span>\n\n<span class=\"ansi-red-fg\">AnalysisException</span>: Table or view not found: df_valid1; line 1 pos 14;\n&#39;GlobalLimit 100\n+- &#39;LocalLimit 100\n   +- &#39;Project [*]\n      +- &#39;UnresolvedRelation [df_valid1], [], false\n</div>",
       "errorSummary": "<span class=\"ansi-red-fg\">AnalysisException</span>: Table or view not found: df_valid1; line 1 pos 14;",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "select * from df_valid1\n",
    "LIMIT 100"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 2293093804025024,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "Teste - CSC",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
